# RL from Physical Feedback: Aligning Large Motion Models with Humanoid Whole-Body Control

<div align="center">
[[Website]](https://beingbeyond.github.io/RLPF)
[[arXiv]](https://arxiv.org/abs/2410.03311)

[![Python Version](https://img.shields.io/badge/Python-3.10-blue.svg)]()
[![GitHub license](https://img.shields.io/badge/MIT-blue)]()

![](docs/images/motionlib.png)

</div>


We present MotionLib, the first million-level dataset for motion generation, which is at least 15Ã— larger than existing counterparts and enriched with hierarchical text descriptions. Using MotionLib, we train a large motion model named Being-M0, demonstrating robust performance across a wide range of human activities, including unseen ones. More Visualization can be found on our [[Website]](https://beingbeyond.github.io/Being-M0).


## Code
We will release our code and part of our dataset soon.

## Citation
If you find our work useful, please consider citing us!
```
@inproceedings{wang2025scaling,
title={Scaling Motion Generation Models with Million-Level Human Motions},
author={Wang, Ye and Zheng, Sipeng and Cao, Bin and Wei, Qianshan and Zeng, Weishuai and Jin, Qin and Lu, Zongqing},
booktitle={International Conference on Machine Learning (ICML)},
year={2025}
}
```
