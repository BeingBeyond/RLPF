# RL from Physical Feedback: Aligning Large Motion Models with Humanoid Whole-Body Control

<div align="center">
[[Website]](https://beingbeyond.github.io/RLPF)

[![Python Version](https://img.shields.io/badge/Python-3.10-blue.svg)]()
[![GitHub license](https://img.shields.io/badge/MIT-blue)]()

![](docs/images/motionlib.png)

</div>

We propose \textbf{Reinforcement Learning from Physical Feedback (RLPF)}, a novel framework that integrates physics-aware motion evaluation with text-conditioned motion generation.  
RLPF employs a motion tracking policy to assess feasibility in a physics simulator, generating rewards for fine-tuning the motion generator.
This joint optimization ensures both physical plausibility and instruction alignment. 
Furthermore, RLPF introduces an alignment verification module to preserve semantic fidelity to text instructions.
Extensive experiments show that RLPF outperforms baseline methods in generating physically feasible motions, enabling successful deployment on real humanoid platforms.
Our website is available at \url{[https://xxxxxxxxxxxx](https://beingbeyond.github.io/RLPF)}.

## Code
We will release our code and part of our dataset soon.


